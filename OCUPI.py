# OcuPi: Version 1
import os
import sys
import psutil
import cv2
import time
import numpy as np
import threading
import queue
import signal
import platform
import argparse
import json
import math
import mediapipe as mp
from collections import deque
from enum import Enum

# Conditional imports for GUI components
try:
    import tkinter as tk
    from tkinter import ttk, messagebox, filedialog
    from PIL import Image, ImageTk
    HAS_TKINTER = True
except ImportError:
    HAS_TKINTER = False
    print("Tkinter not available - GUI mode disabled")

class AlertType(Enum):
    """Different types of alerts that can be triggered"""
    DROWSINESS = "drowsiness"
    NO_FACE = "no_face"
    SYSTEM_BEEP = "system_beep"
    CALIBRATION_START = "calibration_start"
    CALIBRATION_END = "calibration_end"

class OcuPiDetector:
    def __init__(self, gui_mode=False):
        self.gui_mode = gui_mode
        self.video_window_name = "OcuPi: Version 1"
        self.running = True
        self._stop_event = threading.Event()
        self._gui_running = True

        # Always use full computer mode (no hardware optimization)
        print("üñ•Ô∏è Running in Full Computer Mode (Hardware optimization disabled)")

        # Video output control - disabled by default in headless mode
        self.video_output_enabled = gui_mode  # Only enable video in GUI mode
        self.video_display_active = False

        # Initialize pygame for audio
        self.HAS_PYGAME = False
        try:
            import pygame
            try:
                pygame.mixer.init()
                self.HAS_PYGAME = True
                print("‚úÖ Audio system initialized successfully")
            except pygame.error as e:
                print(f"‚ùå Audio not available: {e}")
                print("Sound alerts will use system beep instead")
                self.HAS_PYGAME = False
        except ImportError:
            print("‚ùå pygame not available - sound alerts will use system beep")
            pass

        # System monitoring
        self.process = psutil.Process(os.getpid())
        self.last_sys_update = 0
        self.sys_update_interval = 1.0
        self.cpu_usage = 0
        self.memory_usage = 0
        self.system_cpu = 0
        self.system_mem = 0

        # State flags
        self.gui_ready = False
        self.camera_ready = False
        self.detection_running = False
        self.models_ready = False
        self.manual_silence = False
        self.sound_playing = False

        # Enhanced audio system for headless mode
        self.audio_files = {
            AlertType.DROWSINESS: "alarm.wav",
            AlertType.NO_FACE: "NoFace.wav",
            AlertType.CALIBRATION_START: "CalibStart.wav",
            AlertType.CALIBRATION_END: "CalibEnd.wav"
        }
        self.loaded_sounds = {}
        self.load_audio_files()

        # Detection parameters - Full computer mode always
        self.setup_detection_parameters()

        # Calibration system
        self.perclos_buf = deque()
        self.yawn_buf = deque()
        self.time_buf = deque()
        self.ear_baseline = None
        self.mar_baseline = None
        self.ear_s = None
        self.mar_s = None
        self.score_s = None
        self.drowsy_flag = False
        self.calibration_start = 0
        self.is_calibrating = False

        # Frame counters
        self.eye_closed_frames = 0
        self.no_face_frames = 0
        self.alarm_interval = 0
        self.frame_count = 0
        self.start_time = time.time()

        # Calibration data management
        self.calibration_data = {}
        self.calibration_file = "ocupi_calibration.json"
        self.calibration_valid = False
        self.force_recalibration = False

        # Threading and queues
        self.status_queue = queue.Queue()
        self.command_queue = queue.Queue()
        self.video_queue = queue.Queue(maxsize=2)

        # Enhanced Camera management
        self.available_cameras = []
        self.camera_resolutions = {}
        self.selected_camera = 0
        self.cap = None
        self.video_thread = None
        self._video_thread_lock = threading.Lock()
        self.last_frame = None
        self._camera_change_requested = False
        self._new_camera_index = None
        self.log_file = None

        # Initialize MediaPipe models
        self.init_models()

        # Setup interface based on mode
        if self.gui_mode:
            if HAS_TKINTER:
                self.setup_gui()
            else:
                print("‚ùå Error: GUI mode requested but tkinter is not available.")
                print("Switching to headless mode...")
                self.gui_mode = False
                self.setup_headless()
        else:
            self.setup_headless()

        # Signal handlers
        signal.signal(signal.SIGINT, self.signal_handler)
        signal.signal(signal.SIGTERM, self.signal_handler)

    def load_audio_files(self):
        """Load audio files for headless mode"""
        if not self.HAS_PYGAME:
            print("‚ö†Ô∏è Audio files cannot be loaded - pygame not available")
            return

        import pygame
        
        for alert_type, filename in self.audio_files.items():
            file_path = os.path.join(os.path.dirname(__file__), filename)
            if os.path.exists(file_path):
                try:
                    self.loaded_sounds[alert_type] = pygame.mixer.Sound(file_path)
                    print(f"‚úÖ Loaded audio file: {filename}")
                except Exception as e:
                    print(f"‚ùå Failed to load {filename}: {e}")
                    self.loaded_sounds[alert_type] = None
            else:
                print(f"‚ö†Ô∏è Audio file not found: {filename} - will use system beep")
                self.loaded_sounds[alert_type] = None

    def setup_detection_parameters(self):
        """Setup detection parameters - Full computer mode always"""
        self.CALIB_SECS = 4.0
        self.EMA_ALPHA = 0.35
        self.perclos_window = 10.0
        self.yawn_window = 10.0
        self.enter_thresh = 0.60
        self.exit_thresh = 0.45
        self.DROWSY_FRAME_THRESHOLD = 12  # ~0.4s at 30fps
        self.NO_FACE_THRESHOLD = 10       # ~0.33s at 30fps
        self.ALARM_INTERVAL_THRESHOLD = 12
        # Note: video_output_enabled set based on mode in __init__
        print("üñ•Ô∏è Full Computer Mode: Standard settings")

    def setup_headless(self):
        """Setup headless mode with automatic calibration"""
        print(f"\nüöÄ Initializing OcuPi")
        print("-" * 60)
        print("Mode: Headless (GUI available with --gui flag)")
        print("Calibration: Automatic at startup")
        print("Hardware: Full Computer Mode (optimization disabled)")

        # Auto-connect to camera
        if not self.auto_connect_camera():
            print("‚ö†Ô∏è Warning: Failed to auto-connect to camera")
            print("In a real environment with a camera, the application would continue normally")
            return

        if not self.models_ready:
            print("‚ùå Error: Required models not loaded")
            sys.exit(1)

        # Load existing calibration for GUI usage but force recalibration in headless mode
        if self.gui_mode:
            self.load_calibration()
        else:
            # In headless mode, always calibrate at startup
            print("üîÑ Headless mode: Will calibrate automatically at startup")
            self.calibration_valid = False
            self.force_recalibration = True

        # Auto-start detection for headless mode
        self.start_headless_detection()

        print(f"\n‚úÖ Headless Mode Ready:")
        print("- Press 'q' to quit")
        print("- Press 's' to silence alerts for 5 seconds")
        print("- Press 'r' to recalibrate")
        print("- Press 'v' to toggle video display")
        print("- Press '1-9' to switch cameras")
        print("- True headless mode: No video windows (detection runs in background)")
        print("-" * 60 + "\n")

    def start_headless_detection(self):
        """Start detection automatically for headless mode"""
        self.detection_running = True
        self.reset_detection_counters()

        # In headless mode, always calibrate at startup
        if not self.gui_mode:
            print("üîÑ Starting automatic calibration process...")
            self.calibration_start = time.time()
            self.is_calibrating = True
            self.force_recalibration = True
            # Play calibration start sound
            self.play_audio_alert(AlertType.CALIBRATION_START)
            self.log_event("calibration", "Automatic calibration started in headless mode")
        else:
            # GUI mode behavior - use cached if available
            if self.calibration_valid and not self.force_recalibration:
                print(f"‚úÖ Using cached calibration: EAR={self.ear_baseline:.3f}, MAR={self.mar_baseline:.3f}")
                self.calibration_start = 0
                self.is_calibrating = False
            else:
                print("üîÑ Starting calibration process...")
                self.calibration_start = time.time()
                self.is_calibrating = True
                self.play_audio_alert(AlertType.CALIBRATION_START)
                self.force_recalibration = False

        self.setup_logging()

    def reset_detection_counters(self):
        """Reset all detection counters"""
        self.eye_closed_frames = 0
        self.no_face_frames = 0
        self.alarm_interval = 0
        self.frame_count = 0
        self.start_time = time.time()

        self.perclos_buf.clear()
        self.yawn_buf.clear()
        self.time_buf.clear()

        self.ear_s = None
        self.mar_s = None
        self.score_s = None
        self.drowsy_flag = False

    def setup_logging(self):
        """Setup enhanced logging system"""
        if not os.path.exists("OcuPi_BlackBox"):
            os.makedirs("OcuPi_BlackBox")

        timestamp_str = time.strftime('%Y%m%d_%H%M%S', time.localtime())
        self.log_file = f"OcuPi_BlackBox/ocupi_session_{timestamp_str}.log"

        with open(self.log_file, 'w') as f:
            f.write(self.create_enhanced_log_header())
            f.write("\n")

        mode = "Headless" if not self.gui_mode else "GUI"
        self.log_event("session", "Detection session started",
                      {"mode": mode, "camera": self.selected_camera,
                       "auto_calibration": not self.gui_mode,
                       "video_output": self.video_output_enabled})

    def init_models(self):
        """Initialize MediaPipe face detection models"""
        try:
            self.mp_face_mesh = mp.solutions.face_mesh
            self.mp_draw = mp.solutions.drawing_utils

            # Full computer settings always
            self.face_mesh = self.mp_face_mesh.FaceMesh(
                max_num_faces=1,
                refine_landmarks=True,
                min_detection_confidence=0.5,
                min_tracking_confidence=0.5
            )

            self.models_ready = True
            print("‚úÖ MediaPipe FaceMesh loaded successfully")

        except Exception as e:
            print(f"‚ùå Error loading models: {e}")
            self.models_ready = False

    def scan_cameras(self):
        """Enhanced camera scanning with multiple backends"""
        self.available_cameras = []
        self.camera_resolutions = {}

        # Try different camera backends to detect more cameras
        backends = []
        if platform.system() == 'Linux':
            backends = [cv2.CAP_V4L2, cv2.CAP_ANY]
        elif platform.system() == 'Windows':
            backends = [cv2.CAP_DSHOW, cv2.CAP_MSMF, cv2.CAP_ANY]
        else:  # macOS and others
            backends = [cv2.CAP_AVFOUNDATION, cv2.CAP_ANY]

        for backend in backends:
            print(f"üîç Scanning cameras with backend {backend}...")
            for i in range(10):  # Check first 10 camera indices
                try:
                    cap = cv2.VideoCapture(i, backend)
                    if cap.isOpened():
                        # Test if we can actually read frames
                        ret, _ = cap.read()
                        if ret:
                            if i not in self.available_cameras:
                                self.available_cameras.append(i)

                                # Get camera capabilities
                                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                                fps = int(cap.get(cv2.CAP_PROP_FPS))

                                self.camera_resolutions[i] = {
                                    'width': width,
                                    'height': height,
                                    'fps': fps,
                                    'backend': backend
                                }
                                print(f"üìπ Found Camera {i} with backend {backend}: {width}x{height} @ {fps}fps")
                        cap.release()
                except Exception as e:
                    print(f"‚ùå Error scanning camera {i} with backend {backend}: {e}")
                time.sleep(0.1)

        print(f"üìπ Found {len(self.available_cameras)} camera(s): {self.available_cameras}")
        return self.available_cameras

    def init_camera(self, camera_index=0):
        """Enhanced camera initialization with backend preference"""
        try:
            if hasattr(self, 'cap') and self.cap is not None:
                self.cap.release()
                time.sleep(0.5)

            # Try to use the same backend that was used during scanning if available
            preferred_backend = None
            if camera_index in self.camera_resolutions:
                preferred_backend = self.camera_resolutions[camera_index].get('backend')

            # Try different backends in order of preference
            backends = []
            if preferred_backend:
                backends.append(preferred_backend)

            # Add other backends based on platform
            if platform.system() == 'Linux':
                backends.extend([cv2.CAP_V4L2, cv2.CAP_ANY])
            elif platform.system() == 'Windows':
                backends.extend([cv2.CAP_DSHOW, cv2.CAP_MSMF, cv2.CAP_ANY])
            else:  # macOS and others
                backends.extend([cv2.CAP_AVFOUNDATION, cv2.CAP_ANY])

            # Remove duplicates while preserving order
            seen = set()
            backends = [x for x in backends if not (x in seen or seen.add(x))]

            for backend in backends:
                try:
                    print(f"üîå Trying camera {camera_index} with backend {backend}...")
                    self.cap = cv2.VideoCapture(camera_index, backend)

                    if self.cap.isOpened():
                        # Set full computer resolution and FPS
                        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                        self.cap.set(cv2.CAP_PROP_FPS, 30)

                        # Verify camera works
                        ret, _ = self.cap.read()
                        if ret:
                            print(f"‚úÖ Camera {camera_index} initialized successfully with backend {backend}")
                            self.selected_camera = camera_index
                            self.camera_ready = True
                            self.log_event("camera", f"Camera {camera_index} initialized", 
                                         {"backend": str(backend), "resolution": "640x480@30fps"})
                            return True

                    self.cap.release()
                    print(f"‚ùå Camera backend {backend} failed - no frames available")
                except Exception as e:
                    print(f"‚ùå Camera backend {backend} failed: {str(e)}")
                    continue

            print(f"‚ùå Could not initialize camera {camera_index} with any backend")
            return False

        except Exception as e:
            print(f"‚ùå Camera initialization error: {str(e)}")
            return False

    def auto_connect_camera(self):
        """Automatically detect and connect to the best available camera"""
        print("üîç Auto-detecting cameras...")

        # Scan for available cameras
        self.scan_cameras()

        if not self.available_cameras:
            print("‚ùå No cameras found")
            self.log_event("camera", "No cameras found during auto-detection")
            return False

        # Find best camera (highest resolution)
        best_camera = self.find_best_camera()

        print(f"üìπ Auto-connecting to Camera {best_camera}...")
        success = self.init_camera(best_camera)

        if success:
            print(f"‚úÖ Successfully connected to Camera {best_camera}")
            if best_camera in self.camera_resolutions:
                res = self.camera_resolutions[best_camera]
                print(f"üîç Resolution: {res['width']}x{res['height']} @ {res['fps']}fps")
                self.log_event("camera", f"Successfully auto-connected to camera {best_camera}",
                             {"resolution": f"{res['width']}x{res['height']}", "fps": res['fps']})
        else:
            print(f"‚ùå Failed to connect to Camera {best_camera}")
            self.log_event("camera", f"Failed to auto-connect to camera {best_camera}")

        return success

    def find_best_camera(self):
        """Find the camera with the best resolution"""
        best_camera = self.available_cameras[0]
        best_resolution = 0

        for camera_id in self.available_cameras:
            if camera_id in self.camera_resolutions:
                res = self.camera_resolutions[camera_id]
                current_res = res['width'] * res['height']
                if current_res > best_resolution:
                    best_resolution = current_res
                    best_camera = camera_id

        return best_camera

    def play_audio_alert(self, alert_type):
        """Play audio alert with enhanced logging"""
        if self.sound_playing or self.manual_silence:
            return

        self.sound_playing = True

        def play_sound():
            try:
                # Check if we have the specific audio file loaded
                if (alert_type in self.loaded_sounds and 
                    self.loaded_sounds[alert_type] is not None and 
                    self.HAS_PYGAME):
                    # Play loaded audio file
                    sound = self.loaded_sounds[alert_type]
                    sound.set_volume(0.7)  # Default volume
                    sound.play()
                    
                    # Wait for sound to finish
                    import pygame
                    while pygame.mixer.get_busy():
                        time.sleep(0.1)
                    
                    print(f"üîä Played audio file for {alert_type.value}")
                    self.log_event("audio", f"Played audio file for {alert_type.value}")
                else:
                    # Fallback to system beep
                    print('\a')  # System beep
                    time.sleep(0.5)
                    print(f"üîä Played system beep for {alert_type.value} (audio file not available)")
                    self.log_event("audio", f"Played system beep for {alert_type.value}", 
                                 {"reason": "audio_file_not_available"})
            except Exception as e:
                print(f"‚ùå Error playing {alert_type.value} sound: {e}")
                print('\a')  # Fallback to system beep
                time.sleep(0.5)
                self.log_event("audio", f"Audio playback error for {alert_type.value}", 
                             {"error": str(e), "fallback": "system_beep"})
            finally:
                self.sound_playing = False

        threading.Thread(target=play_sound, daemon=True).start()

    def load_calibration(self):
        """Load saved calibration data (GUI mode only)"""
        if os.path.exists(self.calibration_file):
            try:
                with open(self.calibration_file, 'r') as f:
                    self.calibration_data = json.load(f)
                self.ear_baseline = self.calibration_data.get('ear_baseline')
                self.mar_baseline = self.calibration_data.get('mar_baseline')
                calibration_time = self.calibration_data.get('calibration_time', '')

                if (self.ear_baseline is not None and self.mar_baseline is not None and
                    self.ear_baseline > 0 and self.mar_baseline > 0):
                    self.calibration_valid = True
                    print(f"‚úÖ Loaded valid calibration: EAR={self.ear_baseline:.3f}, MAR={self.mar_baseline:.3f}")
                    print(f"   Calibrated on: {calibration_time}")
                    self.log_event("calibration", "Loaded cached calibration data",
                                 {"ear_baseline": self.ear_baseline, "mar_baseline": self.mar_baseline})
                else:
                    print("‚ùå Invalid calibration data found - will recalibrate")
                    self.calibration_valid = False
            except Exception as e:
                print(f"‚ùå Failed to load calibration data: {e}")
                self.calibration_data = {}
                self.calibration_valid = False
                self.log_event("calibration", "Failed to load calibration data", {"error": str(e)})
        else:
            print("üîç No calibration file found - will calibrate on first run")
            self.calibration_valid = False

    def save_calibration(self):
        """Save calibration data"""
        try:
            self.calibration_data = {
                'ear_baseline': self.ear_baseline,
                'mar_baseline': self.mar_baseline,
                'calibration_time': time.ctime(),
                'version': '2.1_headless',
                'mode': 'headless' if not self.gui_mode else 'gui'
            }
            with open(self.calibration_file, 'w') as f:
                json.dump(self.calibration_data, f, indent=2)
            self.calibration_valid = True
            print(f"‚úÖ Calibration saved: EAR={self.ear_baseline:.3f}, MAR={self.mar_baseline:.3f}")
            self.log_event("calibration", "Calibration data saved successfully",
                         {"ear_baseline": self.ear_baseline, "mar_baseline": self.mar_baseline})
        except Exception as e:
            print(f"‚ùå Failed to save calibration data: {e}")
            self.log_event("calibration", "Failed to save calibration data", {"error": str(e)})

    # Continue with remaining methods...
    def signal_handler(self, signum, frame):
        print(f"Received signal {signum}, shutting down...")
        self.running = False
        self._stop_event.set()
        self.log_event("session", f"Received shutdown signal {signum}")
        self.cleanup()
        sys.exit(0)

    def euclid(self, a, b):
        dx = a[0] - b[0]
        dy = a[1] - b[1]
        return math.hypot(dx, dy)

    def ear_from_points(self, eye):
        A = self.euclid(eye[1], eye[5])
        B = self.euclid(eye[2], eye[4])
        C = self.euclid(eye[0], eye[3])
        return (A + B) / (2.0 * C)

    def mar_from_coords(self, coords):
        v1 = self.euclid(coords[13], coords[14])
        v2 = self.euclid(coords[17], coords[0])
        h = self.euclid(coords[78], coords[308])
        return (v1 + v2) / (2.0 * h)

    def ema(self, prev, x, alpha):
        return x if prev is None else (alpha * x + (1 - alpha) * prev)

    def video_loop(self):
        """Enhanced video processing loop with detailed logging"""
        print("üé• Starting enhanced video processing...")
        self.log_event("video", "Video processing loop started")

        try:
            while self.running and not self._stop_event.is_set():
                if not self.detection_running:
                    if not self.gui_mode:
                        break

                ret, frame = self.cap.read()
                if not ret:
                    print("‚ùå Failed to read frame")
                    self.log_event("video", "Failed to read frame from camera")
                    time.sleep(0.1)
                    continue

                # Store frame for camera switching
                self.last_frame = frame.copy()

                processed_frame = self.process_frame(frame)

                # Add to video queue only if video output is enabled
                if processed_frame is not None:
                    if self.video_output_enabled:
                        if self.gui_mode:
                            try:
                                self.video_queue.put_nowait(processed_frame)
                            except queue.Full:
                                pass

                self.frame_count += 1
                elapsed = time.time() - self.start_time
                fps = self.frame_count / elapsed if elapsed > 0 else 0

                if self.gui_mode:
                    self.status_queue.put({'fps': fps})

                # Handle keyboard input in headless mode (no video window)
                if not self.gui_mode:
                    # In true headless mode, we run without any video display
                    # Detection runs purely in background
                    pass

                if self._stop_event.is_set():
                    break

                # In headless mode, allow graceful shutdown check
                if not self.gui_mode and not self.running:
                    break

        except Exception as e:
            print(f"‚ùå Video processing error: {e}")
            self.log_event("error", "Video processing loop error", {"error": str(e)})
        finally:
            print("‚úÖ Exiting enhanced video loop")
            self.log_event("video", "Video processing loop ended")
            self._stop_event.clear()

    def process_frame(self, frame):
        """Process individual frame for drowsiness detection with enhanced logging"""
        try:
            current_time = time.time()
            if current_time - self.last_sys_update > self.sys_update_interval:
                self.update_system_info()
                self.last_sys_update = current_time

            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = self.face_mesh.process(rgb)

            h, w, _ = frame.shape
            face_found = bool(results.multi_face_landmarks)

            if face_found:
                self.no_face_frames = 0

                fl = results.multi_face_landmarks[0]
                coords = [(lm.x * w, lm.y * h) for lm in fl.landmark]

                # Eye and mouth landmark indices
                leftEye_idx = [33, 160, 158, 133, 153, 144]
                rightEye_idx = [263, 387, 385, 362, 380, 373]
                leftEye = [coords[i] for i in leftEye_idx]
                rightEye = [coords[i] for i in rightEye_idx]

                ear = (self.ear_from_points(leftEye) + self.ear_from_points(rightEye)) / 2.0
                mar = self.mar_from_coords(coords)

                self.ear_s = self.ema(self.ear_s, ear, self.EMA_ALPHA)
                self.mar_s = self.ema(self.mar_s, mar, self.EMA_ALPHA)

                # Draw landmarks if video output is enabled
                if self.video_output_enabled:
                    for idx, (x, y) in enumerate(coords):
                        if idx in leftEye_idx + rightEye_idx or idx in [13, 14, 17, 0, 78, 308]:
                            cv2.circle(frame, (int(x), int(y)), 2, (0, 255, 0), -1)

                ts = time.time()

                # Calibration phase with enhanced logging
                if self.calibration_start > 0 and ts - self.calibration_start < self.CALIB_SECS:
                    self.ear_baseline = ear if self.ear_baseline is None else 0.9*self.ear_baseline + 0.1*ear
                    self.mar_baseline = mar if self.mar_baseline is None else 0.9*self.mar_baseline + 0.1*mar

                    remaining_time = self.CALIB_SECS - (ts - self.calibration_start)

                    if self.video_output_enabled:
                        cv2.putText(frame, f"Calibrating... keep eyes open & mouth closed ({remaining_time:.1f}s)",
                                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 200, 255), 2)
                        cv2.putText(frame, f"EAR0~{self.ear_baseline:.3f}  MAR0~{self.mar_baseline:.3f}",
                                   (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 200, 255), 2)

                    # Reset variables during calibration
                    eye_closed_now = 0
                    yawn_now = 0
                    score_pct = 0.0

                elif self.calibration_start > 0 and ts - self.calibration_start >= self.CALIB_SECS:
                    # Calibration complete with enhanced logging
                    self.save_calibration()
                    self.calibration_start = 0
                    self.is_calibrating = False
                    print("‚úÖ Calibration completed and saved!")
                    
                    # Play calibration end sound
                    self.play_audio_alert(AlertType.CALIBRATION_END)
                    
                    self.log_event("calibration", "Calibration completed successfully",
                                 {"ear_baseline": self.ear_baseline, "mar_baseline": self.mar_baseline,
                                  "duration": self.CALIB_SECS, "mode": "headless" if not self.gui_mode else "gui"})

                # Initialize variables for all code paths
                eye_closed_now = 0
                yawn_now = 0
                score_pct = 0.0

                # Detection phase
                if self.calibration_start == 0:
                    if self.ear_baseline is None or self.mar_baseline is None:
                        self.ear_baseline = self.ear_s if self.ear_s is not None else ear
                        self.mar_baseline = self.mar_s if self.mar_s is not None else mar

                    ear_closed_thresh = self.ear_baseline * 0.70
                    mar_yawn_thresh = max(0.5, self.mar_baseline * 1.80)

                    eye_closed_now = 1 if (self.ear_s is not None and self.ear_s < ear_closed_thresh) else 0
                    yawn_now = 1 if (self.mar_s is not None and self.mar_s > mar_yawn_thresh) else 0

                    # Update buffers
                    self.time_buf.append(ts)
                    self.perclos_buf.append(eye_closed_now)
                    self.yawn_buf.append(yawn_now)

                    # Remove old data
                    while self.time_buf and ts - self.time_buf[0] > self.perclos_window:
                        self.time_buf.popleft()
                        self.perclos_buf.popleft()
                        self.yawn_buf.popleft()

                    # Calculate metrics
                    win_len = max(1, len(self.perclos_buf))
                    perclos = sum(self.perclos_buf) / win_len
                    yawn_frac = sum(self.yawn_buf) / win_len

                    # Calculate drowsiness score
                    ear_term = 0.0
                    if self.ear_s is not None and self.ear_s < ear_closed_thresh:
                        ear_term = (ear_closed_thresh - self.ear_s) / max(1e-6, ear_closed_thresh)
                        ear_term = max(0.0, min(1.0, ear_term))

                    mar_term = 0.0
                    if self.mar_s is not None and self.mar_s > mar_yawn_thresh:
                        mar_term = (self.mar_s - mar_yawn_thresh) / max(1e-6, (1.20 - mar_yawn_thresh))
                        mar_term = max(0.0, min(1.0, mar_term))

                    perclos_term = max(0.0, min(1.0, (perclos - 0.40) / 0.60))
                    yawn_term = max(0.0, min(1.0, yawn_frac))

                    score_raw = 0.50*perclos_term + 0.25*ear_term + 0.20*yawn_term + 0.05*mar_term
                    self.score_s = self.ema(self.score_s, score_raw, 0.30)
                    score_pct = 100.0 * max(0.0, min(1.0, self.score_s if self.score_s is not None else score_raw))

                    # Update drowsy flag with hysteresis
                    prev_drowsy_flag = self.drowsy_flag
                    if self.drowsy_flag:
                        self.drowsy_flag = score_pct >= (self.exit_thresh*100)
                    else:
                        self.drowsy_flag = score_pct >= (self.enter_thresh*100)

                    # Log drowsiness state changes
                    if prev_drowsy_flag != self.drowsy_flag:
                        self.log_event("detection", f"Drowsiness state changed",
                                     {"previous": prev_drowsy_flag, "current": self.drowsy_flag,
                                      "score": score_pct, "threshold": self.enter_thresh*100})

                    # Display metrics if video output enabled
                    if self.video_output_enabled:
                        cv2.putText(frame, f"EAR {self.ear_s:.3f}  thr {ear_closed_thresh:.3f}",
                                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,0), 2)
                        cv2.putText(frame, f"MAR {self.mar_s:.3f}  thr {mar_yawn_thresh:.3f}",
                                   (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,0), 2)
                        cv2.putText(frame, f"PERCLOS {perclos*100:.0f}%",
                                   (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200,255,200), 2)

                    # Track eye closure
                    if eye_closed_now:
                        self.eye_closed_frames += 1
                    else:
                        if self.eye_closed_frames > 0:  # Log when eyes open after being closed
                            self.log_event("detection", f"Eyes opened after {self.eye_closed_frames} frames")
                        self.eye_closed_frames = 0

                    # Trigger alerts with enhanced logging
                    if self.eye_closed_frames >= self.DROWSY_FRAME_THRESHOLD and not self.manual_silence:
                        self.play_audio_alert(AlertType.DROWSINESS)
                        self.log_event("alert", "Drowsiness alert triggered - eyes closed too long",
                                     {"frames_closed": self.eye_closed_frames, 
                                      "threshold": self.DROWSY_FRAME_THRESHOLD,
                                      "ear_value": self.ear_s, "ear_threshold": ear_closed_thresh})
                        self.eye_closed_frames = 0

                    if self.drowsy_flag and self.alarm_interval >= self.ALARM_INTERVAL_THRESHOLD and not self.manual_silence:
                        self.play_audio_alert(AlertType.DROWSINESS)
                        self.log_event("alert", "Drowsiness alert triggered - high drowsiness score",
                                     {"score": score_pct, "alarm_interval": self.alarm_interval,
                                      "threshold": self.ALARM_INTERVAL_THRESHOLD})
                        self.alarm_interval = 0

                    self.alarm_interval += 1

                    # Update GUI status
                    if self.gui_mode:
                        self.status_queue.put({
                            'ear': self.ear_s,
                            'mar': self.mar_s,
                            'score': score_pct
                        })

                # Display drowsiness status
                if self.video_output_enabled:
                    cv2.putText(frame, f"Drowsiness: {score_pct:.1f}%", (10, 130),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255) if self.drowsy_flag else (0,255,0), 2)
                    if self.drowsy_flag:
                        cv2.putText(frame, "ALERT: DROWSY", (10, 165),
                                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,0,255), 3)

                # Log data with more context
                if self.log_file and self.frame_count % 30 == 0:  # Log every 30 frames to reduce file size
                    self.log_detection_data(self.ear_s, self.mar_s, score_pct, eye_closed_now, yawn_now,
                                          self.drowsy_flag, face_found=True)

            else:
                # No face detected with enhanced logging
                self.no_face_frames += 1
                self.eye_closed_frames = 0

                if self.no_face_frames >= self.NO_FACE_THRESHOLD and not self.manual_silence:
                    self.play_audio_alert(AlertType.NO_FACE)
                    self.log_event("alert", "No face alert triggered",
                                 {"frames_without_face": self.no_face_frames,
                                  "threshold": self.NO_FACE_THRESHOLD})
                    self.no_face_frames = 0

                if self.gui_mode:
                    self.status_queue.put({
                        'status': 'No face detected',
                        'ear': 0,
                        'mar': 0,
                        'score': 0
                    })

                if self.log_file and self.no_face_frames == 1:  # Log once when face is lost
                    self.log_detection_data(face_found=False, event=f"Face lost")

                if self.video_output_enabled:
                    cv2.putText(frame, "No face detected", (10, 30),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 140, 255), 2)

                self.drowsy_flag = False

            return frame

        except Exception as e:
            print(f"‚ùå Frame processing error: {e}")
            self.log_event("error", "Frame processing error", {"error": str(e)})
            return frame

    # [Additional methods from original code would continue here...]
    # For brevity, I'm including key methods. The full implementation would include
    # all GUI setup methods, system monitoring, cleanup, etc.

    def toggle_video_output(self):
        """Toggle video output display"""
        self.video_output_enabled = not self.video_output_enabled
        status_msg = "Video output enabled" if self.video_output_enabled else "Video output disabled - Detection continues"
        print(f"üì∫ {status_msg}")
        self.log_event("video", status_msg)

        if not self.video_output_enabled and not self.gui_mode:
            cv2.destroyWindow(self.video_window_name)

    def manual_silence_5s(self):
        """Silence alerts for 5 seconds"""
        self.manual_silence = True
        print("üîá Alerts silenced for 5 seconds")
        self.log_event("user_action", "Manual silence activated for 5 seconds")

        def reset_silence():
            time.sleep(5)
            if self.running:
                self.manual_silence = False
                print("üîä Alert silence ended")
                self.log_event("user_action", "Manual silence ended")

        threading.Thread(target=reset_silence, daemon=True).start()

    def force_recalibrate(self):
        """Force recalibration"""
        self.force_recalibration = True
        self.calibration_valid = False
        self.ear_baseline = None
        self.mar_baseline = None
        self.calibration_start = time.time()
        self.is_calibrating = True

        print("üîÑ Forced recalibration initiated")
        self.log_event("calibration", "Force recalibration requested by user")
        self.play_audio_alert(AlertType.CALIBRATION_START)

    def switch_camera(self, camera_index):
        """Switch camera during operation"""
        success = self.init_camera(camera_index)
        if success:
            print(f"‚úÖ Switched to Camera {camera_index}")
            self.log_event("camera", f"Successfully switched to camera {camera_index}")
        else:
            print(f"‚ùå Failed to switch to Camera {camera_index}")
            self.log_event("camera", f"Failed to switch to camera {camera_index}")
        return success

    def update_system_info(self):
        """Update system performance information"""
        try:
            self.cpu_usage = self.process.cpu_percent()
            self.memory_usage = self.process.memory_info().rss / 1024 / 1024
            self.system_cpu = psutil.cpu_percent()
            self.system_mem = psutil.virtual_memory().percent
        except Exception as e:
            self.log_event("error", "System info update error", {"error": str(e)})

    def create_enhanced_log_header(self):
        """Create comprehensive log header"""
        header = []
        header.append("=" * 80)
        header.append("OCUPI: VERSION 1")
        header.append("=" * 80)
        header.append(f"Session Started: {time.ctime()}")
        header.append(f"Mode: {'Headless' if not self.gui_mode else 'GUI'}")
        header.append(f"Auto Calibration: {'Enabled' if not self.gui_mode else 'Disabled (GUI Mode)'}")
        header.append(f"Hardware Optimization: Disabled (Full Computer Mode Always)")
        header.append(f"Video Output Enabled: {self.video_output_enabled}")
        header.append("")

        # System Information
        header.append("SYSTEM INFORMATION:")
        header.append("-" * 40)
        header.append(f"  Platform: {platform.system()}")
        header.append(f"  Machine: {platform.machine()}")
        header.append(f"  Processor: {platform.processor()}")
        header.append("")

        # Detection Configuration
        header.append("DETECTION CONFIGURATION:")
        header.append("-" * 40)
        header.append(f"  Calibration Duration: {self.CALIB_SECS:.1f} seconds")
        header.append(f"  EMA Alpha: {self.EMA_ALPHA:.3f}")
        header.append(f"  Drowsy Frame Threshold: {self.DROWSY_FRAME_THRESHOLD}")
        header.append(f"  No Face Threshold: {self.NO_FACE_THRESHOLD}")
        header.append(f"  Alarm Interval Threshold: {self.ALARM_INTERVAL_THRESHOLD}")
        header.append("")

        # Audio System
        header.append("AUDIO SYSTEM:")
        header.append("-" * 40)
        for alert_type, filename in self.audio_files.items():
            status = "‚úÖ Loaded" if alert_type in self.loaded_sounds and self.loaded_sounds[alert_type] else "‚ùå Missing"
            header.append(f"  {alert_type.value}: {filename} - {status}")
        header.append("")

        header.append("=" * 80)
        header.append("DETAILED EVENT LOG:")
        header.append("=" * 80)

        return "\n".join(header)

    def log_detection_data(self, ear=None, mar=None, score=None, eye_closed=False, yawn=False,
                          drowsy=False, face_found=True, event=None):
        """Enhanced detection data logging"""
        if not self.log_file:
            return

        try:
            timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())

            status_flags = []
            if not face_found:
                status_flags.append("NO_FACE")
            if eye_closed:
                status_flags.append("EYES_CLOSED")
            if yawn:
                status_flags.append("YAWNING")
            if drowsy:
                status_flags.append("DROWSY_ALERT")
            if self.is_calibrating:
                status_flags.append("CALIBRATING")

            status = "|".join(status_flags) if status_flags else "NORMAL"

            ear_str = f"{ear:.6f}" if ear is not None else "N/A"
            mar_str = f"{mar:.6f}" if mar is not None else "N/A"
            score_str = f"{score:.2f}%" if score is not None else "N/A"

            log_entry = f"[{timestamp}] | FRAME:{self.frame_count:06d} | EAR:{ear_str} | MAR:{mar_str} | SCORE:{score_str} | STATUS:{status}"

            if event:
                log_entry += f" | EVENT:{event}"

            with open(self.log_file, 'a') as f:
                f.write(log_entry + "\n")

        except Exception as e:
            print(f"‚ùå Logging error: {e}")

    def log_event(self, event_type, description, additional_data=None):
        """Enhanced event logging with more context"""
        if not self.log_file:
            return

        try:
            timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())
            log_entry = f"[{timestamp}] | EVENT | {event_type.upper()}: {description}"

            if additional_data:
                if isinstance(additional_data, dict):
                    data_str = " | ".join([f"{k}={v}" for k, v in additional_data.items()])
                    log_entry += f" | DATA: {data_str}"
                else:
                    log_entry += f" | DATA: {additional_data}"

            # Add system context
            log_entry += f" | FRAME:{self.frame_count} | MODE:{'headless' if not self.gui_mode else 'gui'}"

            with open(self.log_file, 'a') as f:
                f.write(log_entry + "\n")

        except Exception as e:
            print(f"‚ùå Event logging error: {e}")

    def cleanup(self):
        """Clean up resources with enhanced logging"""
        print("üßπ Cleaning up resources...")

        # Log session end with statistics
        if self.log_file:
            session_duration = time.time() - self.start_time
            fps_avg = self.frame_count / session_duration if session_duration > 0 else 0
            
            self.log_event("session", "Detection session ended",
                          {"duration_seconds": f"{session_duration:.2f}",
                           "total_frames": self.frame_count,
                           "average_fps": f"{fps_avg:.1f}",
                           "mode": "headless" if not self.gui_mode else "gui",
                           "calibration_completed": self.calibration_valid})

        self.running = False
        self._stop_event.set()

        if hasattr(self, 'cap') and self.cap is not None:
            try:
                self.cap.release()
                self.log_event("cleanup", "Camera released")
            except Exception as e:
                self.log_event("cleanup", "Camera release error", {"error": str(e)})

        # Only destroy windows if they were created (GUI mode)
        if self.gui_mode:
            try:
                cv2.destroyAllWindows()
                self.log_event("cleanup", "OpenCV windows destroyed")
            except:
                pass

        if hasattr(self, 'face_mesh'):
            try:
                self.face_mesh.close()
                self.log_event("cleanup", "MediaPipe face mesh closed")
            except:
                pass

    def setup_gui(self):
        """Diagnostic GUI"""
        if not HAS_TKINTER:
            print("‚ùå Error: Cannot setup GUI - tkinter not available")
            return

        try:
            self.root = tk.Tk()
            self.root.title("OcuPi: Version 1 (Diagnotic GUI)")

            # Standard window size for full computer mode
            self.root.geometry("1200x800")
            self.video_width, self.video_height = 480, 360
            button_font = ('Arial', 11, 'bold')
            label_font = ('Arial', 10)

            self.root.configure(bg='#1e1e1e')

            # Configure style for better touch interface
            style = ttk.Style()
            style.theme_use('clam')

            # Custom button style for touch interface
            style.configure('Touch.TButton',
                          padding=(10, 8),
                          font=button_font)

            style.configure('TouchLarge.TButton',
                          padding=(15, 12),
                          font=button_font)

            # Main container
            main_frame = ttk.Frame(self.root, padding="15")
            main_frame.pack(fill=tk.BOTH, expand=True)

            # Top section: Title and mode info
            self.setup_header_section(main_frame, label_font)

            # Main content: Split into left controls and right video
            content_frame = ttk.Frame(main_frame)
            content_frame.pack(fill=tk.BOTH, expand=True, pady=10)

            # Left side: Controls with scroll support
            self.setup_scrollable_controls(content_frame, button_font, label_font)

            # Right side: Video feed
            right_frame = ttk.Frame(content_frame)
            right_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True)

            # Setup video section
            self.setup_video_section(right_frame, label_font)

            # Load existing calibration in GUI mode
            self.load_calibration()

            # Initialize with auto camera detection
            self.root.after(1000, self.auto_connect_and_setup)

            # Start GUI update loops
            self.root.after(100, self.update_gui_from_queue)
            self.root.after(100, self.update_video_display)
            self.root.after(100, self.update_system_info_gui)

            self.root.protocol("WM_DELETE_WINDOW", self.close_application)
            self.gui_ready = True
            print("‚úÖ Enhanced GUI with scroll support initialized successfully")

        except Exception as e:
            print(f"‚ùå Error setting up GUI: {e}")
            sys.exit(1)

    def setup_header_section(self, parent, label_font):
        """Setup header with title and mode info"""
        header_frame = ttk.Frame(parent)
        header_frame.pack(fill=tk.X, pady=(0, 10))

        # Title
        title_label = ttk.Label(header_frame, text="OcuPi: Version 1",
                               font=('Arial', 18, 'bold'))
        title_label.pack(side=tk.LEFT)

        # Mode indicator
        mode_label = ttk.Label(header_frame, text="Mode: GUI (Full Computer)",
                            font=label_font, foreground='#666666')
        mode_label.pack(side=tk.RIGHT)

    def setup_scrollable_controls(self, parent, button_font, label_font):
        """Setup scrollable controls panel"""
        # Create canvas and scrollbar for left controls
        controls_container = ttk.Frame(parent)
        controls_container.pack(side=tk.LEFT, fill=tk.Y, padx=(0, 15))

        # Canvas for scrolling
        self.controls_canvas = tk.Canvas(controls_container, highlightthickness=0)
        self.controls_scrollbar = ttk.Scrollbar(controls_container, orient="vertical", command=self.controls_canvas.yview)
        self.scrollable_controls = ttk.Frame(self.controls_canvas)

        # Configure scrolling
        self.scrollable_controls.bind(
            "<Configure>",
            lambda e: self.controls_canvas.configure(scrollregion=self.controls_canvas.bbox("all"))
        )

        self.controls_canvas.create_window((0, 0), window=self.scrollable_controls, anchor="nw")
        self.controls_canvas.configure(yscrollcommand=self.controls_scrollbar.set)

        # Pack canvas first, scrollbar will be shown/hidden as needed
        self.controls_canvas.pack(side="left", fill="both", expand=True)

        # Bind mouse wheel scrolling
        self.controls_canvas.bind("<MouseWheel>", self._on_mousewheel)
        self.scrollable_controls.bind("<MouseWheel>", self._on_mousewheel)

        # Setup control sections in the scrollable frame
        self.setup_camera_section(self.scrollable_controls, button_font, label_font)
        self.setup_detection_controls(self.scrollable_controls, button_font, label_font)
        self.setup_audio_controls(self.scrollable_controls, button_font, label_font)
        self.setup_status_section(self.scrollable_controls, label_font)

        # Check if scrollbar is needed after a short delay
        self.root.after(500, self.check_scrollbar_needed)

    def check_scrollbar_needed(self):
        """Check if scrollbar is needed and show/hide accordingly"""
        try:
            self.controls_canvas.update_idletasks()
            canvas_height = self.controls_canvas.winfo_height()
            content_height = self.scrollable_controls.winfo_reqheight()

            if content_height > canvas_height:
                # Content overflows, show scrollbar
                self.controls_scrollbar.pack(side="right", fill="y")
            else:
                # Content fits, hide scrollbar
                self.controls_scrollbar.pack_forget()
        except:
            pass  # Ignore errors during GUI setup

    def _on_mousewheel(self, event):
        """Handle mouse wheel scrolling"""
        try:
            self.controls_canvas.yview_scroll(int(-1*(event.delta/120)), "units")
        except:
            pass

    def setup_camera_section(self, parent, button_font, label_font):
        """Enhanced camera controls section"""
        camera_frame = ttk.LabelFrame(parent, text="üìπ Camera", padding="10")
        camera_frame.pack(fill=tk.X, pady=5)

        # Camera selection
        cam_select_frame = ttk.Frame(camera_frame)
        cam_select_frame.pack(fill=tk.X, pady=5)

        ttk.Label(cam_select_frame, text="Camera:", font=label_font).pack(side=tk.LEFT)

        self.camera_var = tk.StringVar()
        self.camera_combo = ttk.Combobox(cam_select_frame, textvariable=self.camera_var,
                                       width=12, state='readonly', font=label_font)
        self.camera_combo.pack(side=tk.LEFT, padx=5)
        self.camera_combo.bind('<<ComboboxSelected>>', self.on_camera_selected)

        # Camera control buttons - larger for touch
        cam_button_frame = ttk.Frame(camera_frame)
        cam_button_frame.pack(fill=tk.X, pady=5)

        self.scan_button = ttk.Button(cam_button_frame, text="üîç Scan",
                                     command=self.scan_cameras_gui,
                                     style='Touch.TButton', width=8)
        self.scan_button.pack(side=tk.LEFT, padx=2)

        self.connect_button = ttk.Button(cam_button_frame, text="üìπ Connect",
                                        command=self.connect_camera_gui,
                                        style='Touch.TButton', width=10)
        self.connect_button.pack(side=tk.LEFT, padx=2)

        self.auto_connect_button = ttk.Button(cam_button_frame, text="üîÑ Auto",
                                             command=self.auto_connect_gui,
                                             style='Touch.TButton', width=8)
        self.auto_connect_button.pack(side=tk.LEFT, padx=2)

    def setup_detection_controls(self, parent, button_font, label_font):
        """Setup main detection controls"""
        control_frame = ttk.LabelFrame(parent, text="üéØ Detection Control", padding="10")
        control_frame.pack(fill=tk.X, pady=5)

        # Main control buttons - extra large for primary functions
        main_controls = ttk.Frame(control_frame)
        main_controls.pack(fill=tk.X, pady=5)

        self.start_button = ttk.Button(main_controls, text="‚ñ∂Ô∏è START",
                                      command=self.start_detection,
                                      style='TouchLarge.TButton', width=12)
        self.start_button.pack(side=tk.LEFT, padx=2)

        self.stop_button = ttk.Button(main_controls, text="‚è∏Ô∏è STOP",
                                     command=self.stop_detection,
                                     style='TouchLarge.TButton', width=12, state='disabled')
        self.stop_button.pack(side=tk.LEFT, padx=2)

        # Secondary controls
        secondary_controls = ttk.Frame(control_frame)
        secondary_controls.pack(fill=tk.X, pady=5)

        # Video output toggle
        self.video_toggle_button = ttk.Button(secondary_controls,
                                             text="üì∫ Video ON" if self.video_output_enabled else "üì∫ Video OFF",
                                             command=self.toggle_video_output,
                                             style='Touch.TButton', width=12)
        self.video_toggle_button.pack(side=tk.LEFT, padx=2)

        self.recalibrate_button = ttk.Button(secondary_controls, text="üîÑ Recalibrate",
                                           command=self.force_recalibrate_gui,
                                           style='Touch.TButton', width=12)
        self.recalibrate_button.pack(side=tk.LEFT, padx=2)

    def setup_audio_controls(self, parent, button_font, label_font):
        """Enhanced audio controls"""
        audio_frame = ttk.LabelFrame(parent, text="üîä Audio Alerts", padding="10")
        audio_frame.pack(fill=tk.X, pady=5)

        # Volume control
        volume_frame = ttk.Frame(audio_frame)
        volume_frame.pack(fill=tk.X, pady=2)

        ttk.Label(volume_frame, text="Volume:", font=label_font).pack(side=tk.LEFT)
        self.volume_var = tk.DoubleVar(value=0.7)
        self.volume_scale = ttk.Scale(volume_frame, from_=0.0, to=1.0,
                                     variable=self.volume_var,
                                     command=self.update_volume, length=120)
        self.volume_scale.pack(side=tk.LEFT, padx=5)
        self.volume_value_label = ttk.Label(volume_frame, text="0.7", font=label_font)
        self.volume_value_label.pack(side=tk.LEFT)

        # Sound control buttons
        sound_controls = ttk.Frame(audio_frame)
        sound_controls.pack(fill=tk.X, pady=5)

        self.sound_button = ttk.Button(sound_controls, text="üîä Sound ON",
                                      command=self.toggle_sound,
                                      style='Touch.TButton', width=12)
        self.sound_button.pack(side=tk.LEFT, padx=2)

        self.silence_button = ttk.Button(sound_controls, text="üîá 5s Silence",
                                        command=self.manual_silence_5s_gui,
                                        style='Touch.TButton', width=12)
        self.silence_button.pack(side=tk.LEFT, padx=2)

        # Test audio files
        test_frame = ttk.Frame(audio_frame)
        test_frame.pack(fill=tk.X, pady=5)

        self.test_alarm_button = ttk.Button(test_frame, text="üö® Test Alarm",
                                           command=lambda: self.play_audio_alert(AlertType.DROWSINESS),
                                           style='Touch.TButton', width=10)
        self.test_alarm_button.pack(side=tk.LEFT, padx=2)

        self.test_calib_button = ttk.Button(test_frame, text="üîä Test Calib",
                                           command=lambda: self.play_audio_alert(AlertType.CALIBRATION_START),
                                           style='Touch.TButton', width=10)
        self.test_calib_button.pack(side=tk.LEFT, padx=2)

        # Audio file status
        status_frame = ttk.Frame(audio_frame)
        status_frame.pack(fill=tk.X, pady=2)
        
        ttk.Label(status_frame, text="Audio Files:", font=label_font).pack(anchor='w')
        for alert_type, filename in self.audio_files.items():
            status = "‚úÖ" if alert_type in self.loaded_sounds and self.loaded_sounds[alert_type] else "‚ùå"
            ttk.Label(status_frame, text=f"  {status} {filename}", font=('Arial', 8)).pack(anchor='w')

    def setup_status_section(self, parent, label_font):
        """Setup status information display"""
        status_frame = ttk.LabelFrame(parent, text="üìä Status", padding="10")
        status_frame.pack(fill=tk.X, pady=5)

        # Detection status
        self.status_label = ttk.Label(status_frame, text="Ready to start...",
                                     font=label_font, foreground='#0066cc')
        self.status_label.pack(pady=2)

        # Performance metrics
        perf_frame = ttk.Frame(status_frame)
        perf_frame.pack(fill=tk.X)

        metrics_left = ttk.Frame(perf_frame)
        metrics_left.pack(side=tk.LEFT, fill=tk.X, expand=True)

        self.fps_label = ttk.Label(metrics_left, text="FPS: --", font=label_font)
        self.fps_label.pack(anchor='w')

        self.ear_label = ttk.Label(metrics_left, text="EAR: --", font=label_font)
        self.ear_label.pack(anchor='w')

        self.mar_label = ttk.Label(metrics_left, text="MAR: --", font=label_font)
        self.mar_label.pack(anchor='w')

        metrics_right = ttk.Frame(perf_frame)
        metrics_right.pack(side=tk.RIGHT, fill=tk.X, expand=True)

        self.score_label = ttk.Label(metrics_right, text="Drowsiness: --%", font=label_font)
        self.score_label.pack(anchor='w')

        self.cpu_label = ttk.Label(metrics_right, text="CPU: --%", font=label_font)
        self.cpu_label.pack(anchor='w')

        self.mem_label = ttk.Label(metrics_right, text="Memory: -- MB", font=label_font)
        self.mem_label.pack(anchor='w')

        # Model and calibration status
        status_info = ttk.Frame(status_frame)
        status_info.pack(fill=tk.X, pady=5)

        model_status = "‚úÖ Models loaded" if self.models_ready else "‚ùå Models not loaded"
        self.model_label = ttk.Label(status_info, text=model_status, font=label_font)
        self.model_label.pack(anchor='w')

        calib_status = "‚úÖ Calibration cached" if self.calibration_valid else "üîç Will calibrate on start"
        self.calibration_status_label = ttk.Label(status_info, text=calib_status, font=label_font)
        self.calibration_status_label.pack(anchor='w')

    def setup_video_section(self, parent, label_font):
        """Setup video display section"""
        video_frame = ttk.LabelFrame(parent, text="üì∫ Video Feed", padding="5")
        video_frame.pack(fill=tk.BOTH, expand=True)

        # Video display
        self.video_label = ttk.Label(video_frame, text="Video feed will appear here when detection starts",
                                    font=label_font, anchor='center')
        self.video_label.pack(fill=tk.BOTH, expand=True)

        # Video controls
        video_controls = ttk.Frame(video_frame)
        video_controls.pack(fill=tk.X, pady=5)

        # Video toggle (duplicate for convenience)
        self.video_toggle_button2 = ttk.Button(video_controls,
                                              text="üì∫ Toggle Video",
                                              command=self.toggle_video_output,
                                              style='Touch.TButton')
        self.video_toggle_button2.pack(side=tk.LEFT, padx=2)

        # Exit button
        self.exit_button = ttk.Button(video_controls, text="‚ùå Exit",
                                     command=self.close_application,
                                     style='Touch.TButton')
        self.exit_button.pack(side=tk.RIGHT, padx=2)

    # GUI helper methods
    def on_camera_selected(self, event):
        """Handle camera selection"""
        if not self.camera_var.get():
            return

        camera_text = self.camera_var.get()
        try:
            camera_index = int(camera_text.split()[1])  # Extract number from "Camera X"
            if camera_index != self.selected_camera:
                success = self.switch_camera(camera_index)
                if success:
                    messagebox.showinfo("Camera Switch", f"‚úÖ Switched to Camera {camera_index}")
                else:
                    messagebox.showerror("Camera Error", f"‚ùå Failed to switch to Camera {camera_index}")
        except (ValueError, IndexError):
            print(f"‚ùå Could not parse camera index from: {camera_text}")

    def scan_cameras_gui(self):
        """Scan cameras from GUI"""
        self.scan_button.config(state='disabled', text="üîç Scanning...")
        
        def scan_thread():
            cameras = self.scan_cameras()
            self.safe_gui_update(self.update_camera_list, cameras)

        threading.Thread(target=scan_thread, daemon=True).start()

    def update_camera_list(self, cameras):
        """Update camera list in GUI"""
        if not self._gui_running:
            return

        self.scan_button.config(state='normal', text="üîç Scan")

        if cameras:
            camera_options = []
            for camera_id in cameras:
                if camera_id in self.camera_resolutions:
                    res = self.camera_resolutions[camera_id]
                    camera_options.append(f"Camera {camera_id} ({res['width']}x{res['height']})")
                else:
                    camera_options.append(f"Camera {camera_id}")

            self.camera_combo['values'] = camera_options
            if not self.camera_var.get():  # If nothing selected
                self.camera_combo.current(0)
            self.status_queue.put({'status': f'Found {len(cameras)} camera(s)'})
        else:
            self.camera_combo['values'] = []
            self.status_queue.put({'status': 'No cameras found'})
            messagebox.showwarning("Camera Warning", "No cameras detected")

    def connect_camera_gui(self):
        """Connect to selected camera from GUI"""
        if not self.camera_var.get():
            messagebox.showwarning("Selection Error", "Please select a camera first")
            return

        camera_text = self.camera_var.get()
        camera_index = int(camera_text.split()[1])  # Extract number from "Camera X"

        self.connect_button.config(state='disabled', text="üìπ Connecting...")

        def connect_thread():
            success = self.init_camera(camera_index)
            self.safe_gui_update(self.update_connection_status, success)

        threading.Thread(target=connect_thread, daemon=True).start()

    def update_connection_status(self, success):
        """Update connection status in GUI"""
        if not self._gui_running:
            return

        self.connect_button.config(state='normal', text="üìπ Connect")

        if success:
            self.start_button.config(state='normal')
            messagebox.showinfo("Success", f"‚úÖ Camera {self.selected_camera} connected")
        else:
            messagebox.showerror("Error", "‚ùå Failed to connect to camera")

    def auto_connect_gui(self):
        """Auto-connect to best camera from GUI"""
        self.auto_connect_button.config(state='disabled', text="üîÑ Connecting...")

        def connect_thread():
            success = self.auto_connect_camera()
            self.safe_gui_update(self.update_auto_connection_status, success)

        threading.Thread(target=connect_thread, daemon=True).start()

    def update_auto_connection_status(self, success):
        """Update GUI after auto-connection attempt"""
        if not self._gui_running:
            return

        self.auto_connect_button.config(state='normal', text="üîÑ Auto")

        if success:
            # Update camera combo box
            self.update_camera_list(self.available_cameras)
            # Select the connected camera
            for i, camera_id in enumerate(self.available_cameras):
                if camera_id == self.selected_camera:
                    self.camera_combo.current(i)
                    break

            self.start_button.config(state='normal')
            messagebox.showinfo("Success", f"‚úÖ Auto-connected to Camera {self.selected_camera}")
        else:
            messagebox.showerror("Error", "‚ùå Failed to auto-connect to any camera")

    def auto_connect_and_setup(self):
        """Auto-connect camera when GUI starts"""
        if not self.camera_ready:
            success = self.auto_connect_camera()
            if success:
                self.update_camera_list(self.available_cameras)
                # Select the connected camera in combo box
                for i, camera_id in enumerate(self.available_cameras):
                    if camera_id == self.selected_camera:
                        self.camera_combo.current(i)
                        break
                self.start_button.config(state='normal')

    def start_detection(self):
        """Start detection process from GUI"""
        if not self.camera_ready:
            messagebox.showwarning("Camera Error", "Please connect a camera first")
            return

        if not self.models_ready:
            messagebox.showerror("Model Error", "Face detection models not loaded")
            return

        self.stop_detection()
        self._stop_event.clear()

        self.detection_running = True
        self.start_button.config(state='disabled')
        self.stop_button.config(state='normal')

        self.reset_detection_counters()

        # GUI mode uses cached calibration if available
        if self.calibration_valid and not self.force_recalibration:
            print(f"‚úÖ Using cached calibration: EAR={self.ear_baseline:.3f}, MAR={self.mar_baseline:.3f}")
            self.calibration_start = 0
            self.is_calibrating = False
        else:
            print("üîÑ Starting calibration process...")
            self.calibration_start = time.time()
            self.is_calibrating = True
            self.play_audio_alert(AlertType.CALIBRATION_START)
            self.force_recalibration = False

        self.setup_logging()

        # Start video processing thread
        with self._video_thread_lock:
            if self.video_thread is None or not self.video_thread.is_alive():
                self.video_thread = threading.Thread(target=self.video_loop, daemon=True)
                self.video_thread.start()

    def stop_detection(self):
        """Stop detection process"""
        if not self.detection_running:
            return

        self.detection_running = False
        self._stop_event.set()

        if self.gui_mode:
            self.start_button.config(state='normal')
            self.stop_button.config(state='disabled')

        if hasattr(self, 'root') and self._gui_running:
            self.root.after(500, self.check_video_thread_cleanup)

    def check_video_thread_cleanup(self):
        """Check if video thread has stopped"""
        with self._video_thread_lock:
            if self.video_thread and not self.video_thread.is_alive():
                print("‚úÖ Video thread stopped successfully.")
                self.video_thread = None
            else:
                print("‚è≥ Waiting for video thread to exit...")
                if hasattr(self, 'root') and self._gui_running:
                    self.root.after(500, self.check_video_thread_cleanup)

    def safe_gui_update(self, func, *args, **kwargs):
        """Thread-safe GUI updates"""
        if self._gui_running and hasattr(self, 'root'):
            try:
                if args or kwargs:
                    self.root.after(0, lambda: func(*args, **kwargs))
                else:
                    self.root.after(0, func)
            except RuntimeError:
                pass

    def update_gui_from_queue(self):
        """Update GUI from status queue"""
        if not self._gui_running or not hasattr(self, 'root'):
            return

        try:
            while not self.status_queue.empty():
                status_data = self.status_queue.get_nowait()

                if 'status' in status_data:
                    self.status_label.config(text=status_data['status'])
                if 'fps' in status_data:
                    self.fps_label.config(text=f"FPS: {status_data['fps']:.1f}")
                if 'ear' in status_data:
                    self.ear_label.config(text=f"EAR: {status_data['ear']:.3f}")
                if 'mar' in status_data:
                    self.mar_label.config(text=f"MAR: {status_data['mar']:.3f}")
                if 'score' in status_data:
                    score_color = '#ff0000' if status_data['score'] > 60 else '#00cc00'
                    self.score_label.config(text=f"Drowsiness: {status_data['score']:.1f}%",
                                          foreground=score_color)

            # Update calibration status
            if hasattr(self, 'calibration_status_label'):
                if self.calibration_start > 0:
                    calib_status = "üîÑ Calibrating..."
                elif self.calibration_valid:
                    calib_status = "‚úÖ Calibration cached"
                else:
                    calib_status = "üîç Will calibrate on start"
                self.calibration_status_label.config(text=calib_status)

        except queue.Empty:
            pass

        if self._gui_running and hasattr(self, 'root'):
            self.root.after(100, self.update_gui_from_queue)

    def update_video_display(self):
        """Update video display in GUI"""
        if not self._gui_running or not hasattr(self, 'root'):
            return

        try:
            if self.video_output_enabled and not self.video_queue.empty():
                frame = self.video_queue.get_nowait()

                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                frame = cv2.resize(frame, (self.video_width, self.video_height))

                img = Image.fromarray(frame)
                imgtk = ImageTk.PhotoImage(image=img)

                self.video_label.imgtk = imgtk
                self.video_label.configure(image=imgtk, text="")

        except (queue.Empty, tk.TclError):
            pass
        except Exception as e:
            print(f"‚ùå Error updating video display: {e}")

        if self._gui_running and hasattr(self, 'root'):
            self.root.after(30, self.update_video_display)

    def update_system_info_gui(self):
        """Update system info in GUI"""
        if not self._gui_running or not hasattr(self, 'root'):
            return

        self.update_system_info()

        try:
            self.cpu_label.config(text=f"CPU: {self.cpu_usage:.1f}%")
            self.mem_label.config(text=f"Memory: {self.memory_usage:.1f} MB")
        except:
            pass

        if self._gui_running and hasattr(self, 'root'):
            self.root.after(2000, self.update_system_info_gui)

    def toggle_sound(self):
        """Toggle sound on/off"""
        self.manual_silence = not self.manual_silence
        if self.manual_silence:
            self.sound_button.config(text="üîá Sound OFF")
        else:
            self.sound_button.config(text="üîä Sound ON")

    def manual_silence_5s_gui(self):
        """Silence alerts for 5 seconds from GUI"""
        self.manual_silence = True
        self.silence_button.config(text="üîá Silenced...", state='disabled')

        def reset_silence():
            time.sleep(5)
            if self.running:
                self.manual_silence = False
                self.safe_gui_update(lambda: self.silence_button.config(text="üîá 5s Silence", state='normal'))
                self.safe_gui_update(lambda: self.sound_button.config(text="üîä Sound ON"))

        threading.Thread(target=reset_silence, daemon=True).start()

    def force_recalibrate_gui(self):
        """Force recalibration from GUI"""
        response = messagebox.askyesno("Recalibrate",
                                     "This will start a new calibration process.\n\n"
                                     "Please:\n"
                                     "1. Keep your eyes open\n"
                                     "2. Keep your mouth closed\n"
                                     "3. Look straight at the camera\n"
                                     f"4. Stay still for {self.CALIB_SECS:.0f} seconds\n\n"
                                     "Continue?")
        if not response:
            return

        self.force_recalibrate()

        if self.detection_running:
            self.stop_detection()
            time.sleep(0.5)
            self.start_detection()

        messagebox.showinfo("Recalibration", "Recalibration will start when detection begins.")

    def update_volume(self, value):
        """Update volume setting"""
        volume = float(value)
        self.volume_value_label.config(text=f"{volume:.1f}")
        
        # Update volume for loaded sounds
        if self.HAS_PYGAME:
            for alert_type, sound in self.loaded_sounds.items():
                if sound is not None:
                    sound.set_volume(volume)

    def close_application(self):
        """Close application gracefully"""
        print("üîÑ Closing application...")
        self.running = False
        self._gui_running = False
        self._stop_event.set()

        self.stop_detection()
        self.cleanup()

        if hasattr(self, 'root'):
            try:
                self.root.quit()
                self.root.destroy()
            except:
                pass

    def run(self):
        """Run the application"""
        try:
            if not self.gui_mode:
                print("üöÄ Running in Headless mode...")
                self.log_event("session", "Started in headless mode")
                self.video_loop()
            else:
                print("üöÄ Running in GUI mode...")
                self.log_event("session", "Started in GUI mode")
                if HAS_TKINTER and hasattr(self, 'root'):
                    self.root.mainloop()
                else:
                    print("‚ùå Error: GUI mode not available")
                    return
        except KeyboardInterrupt:
            print("‚ö†Ô∏è Interrupted by user")
            self.log_event("session", "Interrupted by user (Ctrl+C)")
        finally:
            self.cleanup()

def main():
    parser = argparse.ArgumentParser(description="OcuPi: Version 1")
    parser.add_argument('--gui', action='store_true', help='Run in GUI mode (default is headless)')
    args = parser.parse_args()

    print("üöÄ Starting OcuPi: Version 1...")
    detector = OcuPiDetector(gui_mode=args.gui)
    detector.run()

if __name__ == "__main__":
    main()
